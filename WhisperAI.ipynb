{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# <font color = yellow>**Youtube影片語音辨識**"
      ],
      "metadata": {
        "id": "62t8EZvkmpsN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- <font color = orange> 套件安裝"
      ],
      "metadata": {
        "id": "UB19YmKiRJip"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rpbf79LpGonl",
        "outputId": "431ff8ea-38a0-4a60-fd54-6599daeae179"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/800.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m798.7/800.5 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.6.0)\n",
            "Collecting tiktoken (from openai-whisper)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (3.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->openai-whisper)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m111.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803406 sha256=154f483478b39efbe8dc6602f75efa437cd74d04e2fb8fc0a087aa63d7c9153c\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/f2/ce/6eb23db4091d026238ce76703bd66da60b969d70bcc81d5d3a\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openai-whisper-20240930 tiktoken-0.9.0\n",
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n"
          ]
        }
      ],
      "source": [
        "# 安裝whisper語音辨識工具\n",
        "!pip install -U openai-whisper\n",
        "\n",
        "# 安裝youtube套件\n",
        "!pip install pytube\n",
        "\n",
        "# 安裝yt-dlp套件，yt影片下載器\n",
        "!pip install yt-dlp"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- <font color = orange> 抓取影片"
      ],
      "metadata": {
        "id": "cUFAHv7IRUMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import YouTubeVideo\n",
        "\n",
        "YouTubeVideo('qXwt67lyhsM')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "_PrWjmBWG-p7",
        "outputId": "f5a82360-4058-4c30-aaf5-4fd0e3a59391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.YouTubeVideo at 0x7ce61c0e4b50>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"400\"\n",
              "            height=\"300\"\n",
              "            src=\"https://www.youtube.com/embed/qXwt67lyhsM\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ],
            "image/jpeg": "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\n"
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- <font color = orange>取得影片資訊（確認）"
      ],
      "metadata": {
        "id": "n2Bm-SP4PdeR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yt_dlp\n",
        "\n",
        "url = 'https://www.youtube.com/watch?v=qXwt67lyhsM'\n",
        "\n",
        "ydl_opts = {\n",
        "    'quiet': True,\n",
        "    'skip_download': True,\n",
        "    'forcejson': True\n",
        "}\n",
        "\n",
        "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "    info_dict = ydl.extract_info(url, download=False)\n",
        "    print(\"影片標題：\", info_dict.get('title'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llQ888LmJgLO",
        "outputId": "d0766395-cf19-41dd-b976-ad77e7992205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "影片標題： 家寧正式回應\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- <font color = orange>下載影片"
      ],
      "metadata": {
        "id": "BbNbtwKZPgit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ydl_opts = {\n",
        "    'format': 'bestaudio/best',\n",
        "    'outtmpl': 'test_audio.%(ext)s',\n",
        "    'postprocessors': [{\n",
        "        'key': 'FFmpegExtractAudio',\n",
        "        'preferredcodec': 'm4a',      # .m4a更適合Whisper使用\n",
        "        'preferredquality': '192',\n",
        "    }]\n",
        "}\n",
        "\n",
        "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "    ydl.download([url])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0u_Rf00kHFFP",
        "outputId": "1bd31912-405c-40a0-a622-a6896a3cae33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=qXwt67lyhsM\n",
            "[youtube] qXwt67lyhsM: Downloading webpage\n",
            "[youtube] qXwt67lyhsM: Downloading tv client config\n",
            "[youtube] qXwt67lyhsM: Downloading player 363db69b\n",
            "[youtube] qXwt67lyhsM: Downloading tv player API JSON\n",
            "[youtube] qXwt67lyhsM: Downloading ios player API JSON\n",
            "[youtube] qXwt67lyhsM: Downloading m3u8 information\n",
            "[info] qXwt67lyhsM: Downloading 1 format(s): 251\n",
            "[download] Destination: test_audio.webm\n",
            "[download] 100% of    3.18MiB in 00:00:00 at 8.47MiB/s   \n",
            "[ExtractAudio] Destination: test_audio.m4a\n",
            "Deleting original file test_audio.webm (pass -k to keep)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- <font color = orange>套用Whisper模型"
      ],
      "metadata": {
        "id": "4QApEnm_PCUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "model = whisper.load_model(\"large\")\n",
        "result = model.transcribe(\"test_audio.m4a\", language=\"zh\")\n",
        "\n",
        "print(result[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqjckcRxHJsk",
        "outputId": "2b6fbfa9-574d-47df-cf52-ec9d755ac7e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 2.88G/2.88G [01:04<00:00, 47.9MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "親愛的朋友粉絲們大家好我是佳寧這段時間無論是作為女兒夥伴還是創作者這一切對我來說都不容易我始終珍惜身邊的每一段關係也感謝這些年來一路相伴的家人夥伴及支持我的朋友和粉絲們對於這次的風波我深感遺憾因為這不只是關於公司與個人的問題更是關係到親情與夥伴情誼這段時間我並非選擇逃避而是希望能夠以最負責任的態度去釐清問題去尋求最適當的解決方式我理解大家的關心也感受到各方來致的期待因此想透過這封聲明讓大家了解我的立場與心境一直以來我對於財務方面的細節有所疑問這並非近期才開始關注的事情數年間我曾多次詢問並希望獲得更清楚的資訊以確保自己能夠對公司與個人的發展負責然而至今我能為獲得完整的數據這也是我選擇與專業人士諮詢並努力釐清相關狀況的原因我深信透明與公平是合作的基石因此我希望透過合適的法律程序確保所有的權益與責任都能夠得到合理的處理關於頻道的營運與收入分配過去我更專注於創作將心力投入在內容的產出上卻在這段時間內我實在是不太清楚自己對於財務與經營層面的認識還不夠深入我願意以更成熟的態度學習並確保未來能夠有更清新的規劃與管理在個人關係上我尊重並珍惜過去的每一段經歷也希望彼此都能夠在未來擁有更好的發展分手後我一直努力維持彼此的距離避免不必要的爭議在這裡我想誠實的請求大家給予我們彼此一些空間讓我們能夠用最適合的方式走向各自更好的未來這些年我始終堅持以真誠的態度經營頻道也相信大家能夠看到我的努力我不希望這些傳聞影響到支持我的朋友們因此才選擇站出來說明這次的事件讓我學到了許多作為公眾人物我應該更早意識到經營管理的重要性也應該更早學會如何在事業與家庭之間取得平衡我真誠的向所有因這次事件受到影響的人致歉無論是家人合作夥伴還是一直支持我的你們在未來的路上我帶著這次經驗會更加獨立成長勇敢也更加珍惜每一份支持與陪伴謝謝你們一直以來的關心與鼓勵這份溫暖是我們前進的動力希望我們都能夠在這次風波後迎來更明朗的未來謝謝大家\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- <font color = orange>逐句印出"
      ],
      "metadata": {
        "id": "ZROMfA2UO9PL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for segment in result[\"segments\"]:\n",
        "    start = segment[\"start\"]\n",
        "    end = segment[\"end\"]\n",
        "    text = segment[\"text\"]\n",
        "    print(f\"[{start:.2f} → {end:.2f}] {text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKfxJY2uMm-e",
        "outputId": "ac54b0e3-edbf-40e4-bea8-51eac120e736"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.00 → 2.56] 親愛的朋友粉絲們大家好\n",
            "[2.56 → 4.44] 我是佳寧\n",
            "[4.44 → 5.84] 這段時間\n",
            "[5.84 → 7.64] 無論是作為女兒\n",
            "[7.64 → 8.44] 夥伴\n",
            "[8.44 → 10.24] 還是創作者\n",
            "[10.24 → 12.54] 這一切對我來說\n",
            "[12.54 → 14.08] 都不容易\n",
            "[14.08 → 17.32] 我始終珍惜身邊的每一段關係\n",
            "[17.32 → 20.68] 也感謝這些年來一路相伴的家人\n",
            "[20.68 → 21.62] 夥伴\n",
            "[21.62 → 25.46] 及支持我的朋友和粉絲們\n",
            "[25.46 → 27.40] 對於這次的風波\n",
            "[27.40 → 29.16] 我深感遺憾\n",
            "[29.16 → 31.72] 因為這不只是關於公司\n",
            "[31.72 → 34.16] 與個人的問題\n",
            "[34.16 → 36.34] 更是關係到親情\n",
            "[36.34 → 38.24] 與夥伴情誼\n",
            "[38.24 → 39.64] 這段時間\n",
            "[39.64 → 41.70] 我並非選擇逃避\n",
            "[41.70 → 44.98] 而是希望能夠以最負責任的態度\n",
            "[44.98 → 46.82] 去釐清問題\n",
            "[46.82 → 50.32] 去尋求最適當的解決方式\n",
            "[50.32 → 52.62] 我理解大家的關心\n",
            "[52.62 → 55.72] 也感受到各方來致的期待\n",
            "[55.72 → 57.92] 因此想透過這封聲明\n",
            "[57.92 → 58.92] 讓大家了解\n",
            "[58.92 → 61.22] 我的立場與心境\n",
            "[61.22 → 62.76] 一直以來\n",
            "[62.76 → 65.96] 我對於財務方面的細節有所疑問\n",
            "[65.96 → 69.54] 這並非近期才開始關注的事情\n",
            "[69.54 → 71.20] 數年間\n",
            "[71.20 → 72.74] 我曾多次詢問\n",
            "[72.74 → 75.56] 並希望獲得更清楚的資訊\n",
            "[75.56 → 78.38] 以確保自己能夠對公司\n",
            "[78.38 → 80.68] 與個人的發展負責\n",
            "[80.68 → 82.08] 然而至今\n",
            "[82.08 → 84.78] 我能為獲得完整的數據\n",
            "[84.78 → 88.48] 這也是我選擇與專業人士諮詢\n",
            "[88.92 → 93.02] 並努力釐清相關狀況的原因\n",
            "[93.02 → 97.36] 我深信透明與公平是合作的基石\n",
            "[97.36 → 101.46] 因此我希望透過合適的法律程序\n",
            "[101.46 → 104.54] 確保所有的權益與責任\n",
            "[104.54 → 107.60] 都能夠得到合理的處理\n",
            "[107.60 → 112.22] 關於頻道的營運與收入分配\n",
            "[112.22 → 114.52] 過去我更專注於創作\n",
            "[114.52 → 117.84] 將心力投入在內容的產出上\n",
            "[117.84 → 118.88] 卻在這段時間內\n",
            "[118.92 → 120.46] 我實在是不太清楚\n",
            "[120.46 → 124.56] 自己對於財務與經營層面的認識\n",
            "[124.56 → 126.36] 還不夠深入\n",
            "[126.36 → 129.42] 我願意以更成熟的態度學習\n",
            "[129.42 → 131.46] 並確保未來能夠\n",
            "[131.46 → 135.04] 有更清新的規劃與管理\n",
            "[135.04 → 136.84] 在個人關係上\n",
            "[136.84 → 140.68] 我尊重並珍惜過去的每一段經歷\n",
            "[140.68 → 142.48] 也希望彼此\n",
            "[142.48 → 146.14] 都能夠在未來擁有更好的發展\n",
            "[146.14 → 147.34] 分手後\n",
            "[147.34 → 148.88] 我一直努力維持\n",
            "[148.88 → 150.42] 彼此的距離\n",
            "[150.42 → 152.72] 避免不必要的爭議\n",
            "[152.72 → 154.00] 在這裡\n",
            "[154.00 → 156.82] 我想誠實的請求大家\n",
            "[156.82 → 159.38] 給予我們彼此一些空間\n",
            "[159.38 → 162.20] 讓我們能夠用最適合的方式\n",
            "[162.20 → 165.52] 走向各自更好的未來\n",
            "[165.52 → 166.80] 這些年\n",
            "[166.80 → 168.60] 我始終堅持\n",
            "[168.60 → 171.40] 以真誠的態度經營頻道\n",
            "[171.40 → 174.48] 也相信大家能夠看到我的努力\n",
            "[174.48 → 176.78] 我不希望這些傳聞\n",
            "[176.78 → 178.84] 影響到支持我的朋友們\n",
            "[178.88 → 180.16] 因此\n",
            "[180.16 → 182.46] 才選擇站出來說明\n",
            "[182.46 → 184.26] 這次的事件\n",
            "[184.26 → 186.30] 讓我學到了許多\n",
            "[186.30 → 188.10] 作為公眾人物\n",
            "[188.10 → 191.94] 我應該更早意識到經營管理的重要性\n",
            "[191.94 → 193.98] 也應該更早學會\n",
            "[193.98 → 196.54] 如何在事業與家庭之間\n",
            "[196.54 → 198.34] 取得平衡\n",
            "[198.34 → 199.88] 我真誠的向\n",
            "[199.88 → 201.92] 所有因這次事件\n",
            "[201.92 → 204.22] 受到影響的人致歉\n",
            "[204.22 → 208.84] 無論是家人\n",
            "[208.88 → 210.16] 合作夥伴\n",
            "[210.16 → 212.72] 還是一直支持我的你們\n",
            "[212.72 → 214.26] 在未來的路上\n",
            "[214.26 → 216.04] 我帶著這次經驗\n",
            "[216.04 → 217.58] 會更加獨立\n",
            "[217.58 → 218.36] 成長\n",
            "[218.36 → 219.38] 勇敢\n",
            "[219.38 → 223.22] 也更加珍惜每一份支持與陪伴\n",
            "[223.22 → 224.76] 謝謝你們\n",
            "[224.76 → 227.06] 一直以來的關心與鼓勵\n",
            "[227.06 → 230.38] 這份溫暖是我們前進的動力\n",
            "[230.38 → 231.40] 希望\n",
            "[231.40 → 233.96] 我們都能夠在這次風波後\n",
            "[233.96 → 236.02] 迎來更明朗的未來\n",
            "[238.88 → 239.90] 謝謝大家\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- <font color = orange>存檔：存成逐句分段的文字"
      ],
      "metadata": {
        "id": "EiiBiEkTSoMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"segments.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for seg in result[\"segments\"]:\n",
        "        f.write(f\"[{seg['start']:.2f} → {seg['end']:.2f}] {seg['text']}\\n\")"
      ],
      "metadata": {
        "id": "Fg1-pICZSicJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- <font color = orange>存檔：存成JSON（含完整結構）"
      ],
      "metadata": {
        "id": "oN1td59gSrdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"result.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(result, f, ensure_ascii=False, indent=2)"
      ],
      "metadata": {
        "id": "3lXoIGRbSjjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color = yellow>**字幕.srt檔生成工具**"
      ],
      "metadata": {
        "id": "BCOgY69fyY_z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- <font color = orange>安裝套件"
      ],
      "metadata": {
        "id": "16q199X-yzAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U openai-whisper\n",
        "!sudo apt update && sudo apt install -y ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wR7KMSpwygnb",
        "outputId": "b7c378e8-cf1c-404b-98c8-8a443334fa18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/800.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m757.8/800.5 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.6.0)\n",
            "Collecting tiktoken (from openai-whisper)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (3.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->openai-whisper)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803405 sha256=e117b3cce687b1248946f085c9615147e1628b8a994ec41ca7a7bde7c1fffe46\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/f2/ce/6eb23db4091d026238ce76703bd66da60b969d70bcc81d5d3a\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openai-whisper-20240930 tiktoken-0.9.0\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,381 kB]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,772 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,238 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,680 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,041 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,813 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,698 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [47.7 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,041 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,538 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [55.7 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\n",
            "Fetched 29.7 MB in 3s (9,602 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "35 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- <font color = orange>輸入影音檔案"
      ],
      "metadata": {
        "id": "QTYugoFcy06B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "collapsed": true,
        "id": "hdm5HpbfyjjF",
        "outputId": "dbd8e5f0-80c2-49ee-ab4e-3a730857790c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c58bbccc-dcc7-4160-be86-030dd338b9e8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c58bbccc-dcc7-4160-be86-030dd338b9e8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving test.mov to test.mov\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- <font color = orange>字幕生成"
      ],
      "metadata": {
        "id": "VyPmUIpXy69w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import os\n",
        "from datetime import timedelta\n",
        "import subprocess\n",
        "from google.colab import files\n",
        "\n",
        "# 輸入影片檔名\n",
        "filename = list(uploaded.keys())[0]\n",
        "base_name = os.path.splitext(filename)[0]\n",
        "\n",
        "# 轉成 mp3 音訊（確保 Whisper 能辨識）\n",
        "audio_file = f\"{base_name}_audio.mp3\"\n",
        "!ffmpeg -y -i \"{filename}\" -vn -acodec libmp3lame \"{audio_file}\"\n",
        "\n",
        "# 進行語音辨識\n",
        "model = whisper.load_model(\"large\")\n",
        "result = model.transcribe(audio_file, language=\"en\")  # zh=中文，en=英文\n",
        "\n",
        "# 產出 SRT 字幕檔\n",
        "srt_filename = f\"{base_name}.srt\"\n",
        "\n",
        "def format_srt_timestamp(seconds):\n",
        "    milliseconds = int(seconds * 1000)\n",
        "    hours = milliseconds // (3600 * 1000)\n",
        "    minutes = (milliseconds % (3600 * 1000)) // (60 * 1000)\n",
        "    secs = (milliseconds % (60 * 1000)) // 1000\n",
        "    ms = milliseconds % 1000\n",
        "    return f\"{hours:02}:{minutes:02}:{secs:02},{ms:03}\"\n",
        "\n",
        "with open(srt_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "    for i, seg in enumerate(result[\"segments\"], 1):\n",
        "        if seg[\"avg_logprob\"] < -1.0 or seg[\"no_speech_prob\"] > 0.6:\n",
        "            continue\n",
        "        start = format_srt_timestamp(seg[\"start\"])\n",
        "        end = format_srt_timestamp(seg[\"end\"])\n",
        "        text = seg[\"text\"].strip()\n",
        "        f.write(f\"{i}\\n{start} --> {end}\\n{text}\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWera0dKytnI",
        "outputId": "5ae2c48f-8a75-4815-e88e-ba409ce04cf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'test.mov':\n",
            "  Metadata:\n",
            "    major_brand     : qt  \n",
            "    minor_version   : 0\n",
            "    compatible_brands: qt  \n",
            "    creation_time   : 2025-03-26T14:45:25.000000Z\n",
            "    com.apple.quicktime.displayname: Line_Video\n",
            "  Duration: 00:00:42.82, start: 0.000000, bitrate: 1938 kb/s\n",
            "  Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 960x540, 1803 kb/s, 29.72 fps, 30 tbr, 600 tbn, 1200 tbc (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2025-03-26T14:45:25.000000Z\n",
            "      handler_name    : Core Media Video\n",
            "      vendor_id       : [0][0][0][0]\n",
            "      encoder         : 'avc1'\n",
            "  Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 88 kb/s (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2025-03-26T14:45:25.000000Z\n",
            "      handler_name    : Core Media Audio\n",
            "      vendor_id       : [0][0][0][0]\n",
            "Stream mapping:\n",
            "  Stream #0:1 -> #0:0 (aac (native) -> mp3 (libmp3lame))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, mp3, to 'test_audio.mp3':\n",
            "  Metadata:\n",
            "    major_brand     : qt  \n",
            "    minor_version   : 0\n",
            "    compatible_brands: qt  \n",
            "    com.apple.quicktime.displayname: Line_Video\n",
            "    TSSE            : Lavf58.76.100\n",
            "  Stream #0:0(und): Audio: mp3, 44100 Hz, stereo, fltp (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2025-03-26T14:45:25.000000Z\n",
            "      handler_name    : Core Media Audio\n",
            "      vendor_id       : [0][0][0][0]\n",
            "      encoder         : Lavc58.134.100 libmp3lame\n",
            "size=     670kB time=00:00:42.81 bitrate= 128.2kbits/s speed=55.7x    \n",
            "video:0kB audio:670kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.057737%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 2.88G/2.88G [01:08<00:00, 44.9MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- <font color = orange>存檔：字幕.srt檔"
      ],
      "metadata": {
        "id": "OHRr4TOZzAYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(srt_filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "collapsed": true,
        "id": "1C126CAnyudZ",
        "outputId": "d580c59d-7a59-461c-f429-0778fb6d71b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c54dfe93-bd05-4979-acec-66e67b14974f\", \"test.srt\", 1047)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}